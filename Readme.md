# Predictive Sales Analytics for E-commerce ðŸ›ï¸ðŸ“ˆ

CodificaÃ§Ã£o em Python para uma soluÃ§Ã£o de AnÃ¡lise Preditiva para Vendas de E-commerce. Ele utiliza Apache Airflow para orquestraÃ§Ã£o, Apache Spark para processamento de dados e uma aplicaÃ§Ã£o web para visualizaÃ§Ã£o.

### Docker ðŸ³

Docker Ã© utilizado para containerizar cada componente da soluÃ§Ã£o, garantindo isolamento, reprodutibilidade e escalabilidade. Cada serviÃ§o, seja ele Airflow, Spark ou a aplicaÃ§Ã£o web, Ã© encapsulado em um container Docker, facilitando o deployment, scaling e a manutenÃ§Ã£o.

### Kubernetes â˜¸ï¸

Kubernetes Ã© usado para orquestrar os containers Docker em um ambiente de produÃ§Ã£o. Ele gerencia o ciclo de vida dos containers, auto-healing, auto-scaling e distribuiÃ§Ã£o de carga. Com o Spark no Kubernetes, Ã© possÃ­vel escalar dinamicamente os workers de acordo com a demanda.

### PostgreSQL ðŸ˜

PostgreSQL Ã© o banco de dados escolhido para armazenar metadados do Airflow e, potencialmente, dados de vendas para anÃ¡lise. Ã‰ um sistema de gerenciamento de banco de dados relacional robusto, extensÃ­vel e SQL-compliant.


## PrÃ©-requisitos ðŸ“‹

- Docker e Docker Compose
- Apache Airflow
- Apache Spark
- Python 3.x

## InstalaÃ§Ã£o ðŸš€

1. **Clone o repositÃ³rio**:
   ```b
   git clone https://github.com/your-github-username/Predictive-Sales-Analytics-Ecommerce.git
   cd Predictive-Sales-Analytics-Ecommerce
   ```

2. **Construa as imagens Docker**:
   ```
   docker-compose build
   ```

3. **Instale as dependÃªncias Python** (se estiver executando localmente sem Docker):
   ```
   pip install -r requirements.txt
   ```

## Executando a AplicaÃ§Ã£o ðŸ–¥ï¸

1. **Inicie os serviÃ§os com Docker Compose**:
   ```
   docker-compose up
   ```

2. Acesse a aplicaÃ§Ã£o web em \`http://localhost:8050\` e o Airflow em \`http://localhost:8081\`.

## Inicie a aplicaÃ§Ã£o de forma local com os seguintes comandos:

 - Instalar o Apache Airflow
```
pip install apache-airflow
```

## Inicializar o banco de dados do Airflow
``` 
airflow db init
```

## Criar um usuÃ¡rio admin para acessar a interface web do Airflow
```
airflow users create \
    --username admin \
    --password admin \
    --firstname Admin \
    --lastname Admin \
    --role Admin \
    --email admin@example.com
```
    
## Iniciar o webserver do Airflow
```
airflow webserver -p 8080
```

## Em um novo terminal, iniciar o scheduler do Airflow
airflow scheduler

## Instalar Apache Spark
```
pip install pyspark
```


4. PostgreSQL
- Para instalar o PostgreSQL localmente:

```
sudo apt-get update
```
```
sudo apt-get install postgresql postgresql-contrib
```

- ApÃ³s a instalaÃ§Ã£o, vocÃª pode iniciar o serviÃ§o PostgreSQL:
```
sudo service postgresql start
```

- Crie um banco de dados chamado sales_data:
```
sudo -u postgres createdb sales_data
```

## Para executar a aplicaÃ§Ã£o web:
Instale as dependÃªncias necessÃ¡rias (assumindo que vocÃª tenha um requirements.txt):
```
pip install -r requirements.txt
```

## Execute a aplicaÃ§Ã£o:
```
python main.py
```


## Tecnologias Utilizadas ðŸ› ï¸

- ![Python](https://img.shields.io/badge/-Python-3776AB?style=flat-square&logo=python&logoColor=white) - Linguagem de programaÃ§Ã£o principal.
- ![Spark](https://img.shields.io/badge/-Spark-E25A1C?style=flat-square&logo=apache-spark&logoColor=white) - Para processamento de dados.
- ![Airflow](https://img.shields.io/badge/-Airflow-017CEE?style=flat-square&logo=apache-airflow&logoColor=white) - Para orquestraÃ§Ã£o de tarefas.
- ![Docker](https://img.shields.io/badge/-Docker-2496ED?style=flat-square&logo=docker&logoColor=white) - Para containerizaÃ§Ã£o.


###Sequence Diagram
                    
```seq
Emerson->Brazil: Says Hello 
Note right of Brazil: Brazil thinks\nabout it 
Brazil-->Emerson: How are you? 
Emerson->>Emerson: I am good thanks!
```

echo "README.md Autor:"

Emerson Amorim
