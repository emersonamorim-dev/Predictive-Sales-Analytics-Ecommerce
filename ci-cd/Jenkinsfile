pipeline {
    agent any

    environment {
        // Defina vari√°veis de ambiente, como nome da imagem Docker, tag, etc.
        SPARK_DOCKER_IMAGE = 'my-spark-repo/spark'
        DOCKER_TAG = 'latest'
    }

    stages {
        stage('Build') {
            steps {
                script {
                    // Construa a imagem Docker
                    sh """
                        docker build -t ${SPARK_DOCKER_IMAGE}:${DOCKER_TAG} .
                    """
                    // Envie a imagem para o Docker Hub ou outro registro
                    sh """
                        docker push ${SPARK_DOCKER_IMAGE}:${DOCKER_TAG}
                    """
                }
            }
        }
        stage('Test') {
            steps {
                script {
                    sh "docker run --rm ${SPARK_DOCKER_IMAGE}:${DOCKER_TAG} python -m unittest"
                }
            }
        }
        stage('Deploy') {
            steps {
                script {
                    // Atualize a imagem no spark-deployment.yaml
                    sh """
                        sed -i 's|my-spark-repo/spark:latest|${SPARK_DOCKER_IMAGE}:${DOCKER_TAG}|' spark-deployment.yaml
                    """
                    // Implante o airflow-deployment.yaml
                    sh """
                        kubectl apply -f airflow-deployment.yaml
                    """
                    // Implante o spark-deployment.yaml
                    sh """
                        kubectl apply -f spark-deployment.yaml
                    """
                }
            }
        }
    }
}
